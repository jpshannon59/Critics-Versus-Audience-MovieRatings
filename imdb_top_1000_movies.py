# -*- coding: utf-8 -*-
"""IMDB Top 1000 Movies

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Aaj7NeGIG_fDLUirICB8u4ej-tKzCNIf

In this assignment you can identify a dataset of your interest and perform exploratory data analysis to better understand the data, investigate initial questions about it and develop preliminary insights and hypotheses. Your final submission will be a blog post consisting of a series of captioned visualizations that convey the key insights gained over the course of your analysis. You need to post the blog to medium or your github website.

Documenting the data analysis process you went through is the main pedagogical goal of the assignment and more important than the design of the final visualization.

We will go over the details of the project during class hours next week.

##**Part 1: Select and Prepare the Data**

You should start by picking a topic area of interest to you and finding a dataset that can provide insights into that topic. We have provided some datasets below that you can start from. But we encourage you to investigate a different topic and dataset. If you self-select a dataset and are concerned about its appropriateness for the assignment, you can check with the TAs regarding the same.

**Note:** The data collection and preparation (also known as data wrangling) can be a very tedious and time-consuming process. Be sure you have sufficient time to conduct exploratory analysis, after preparing the data.

After selecting a topic and dataset – but prior to analysis – you should write down an initial set of at least three questions you’d like to investigate.

## **Part 2: Exploratory Analysis**

Once you have picked the dataset and performed the initial data wrangling, you will perform exploratory analysis to investigate your data. For this assignment we would like you to use Pandas, NumPy and matplotlib to help you with the analysis. 

**Phase 1:** You should start the exploration by first examining the shape and structure of your data. What dimensions/variables does it contain and how are the data values distributed? Are there any notable data quality issues? Find out if there are missing values in the data and think of how you can handle them. Are there any surprising relationships between the dimensions/variables? Make sure to perform sanity checks for patterns you expect to see! Note that it may be the case that after doing a bit of exploration in phase 1 you find that your data is not as interesting as you first thought. In such cases you might consider returning to Part 1 and identifying a different dataset to work with. Such iteration on choosing the dataset is common, but also time-consuming, so make sure you leave time in your schedule for this.

**Phase 2:** Next, you should investigate your initial questions, as well as any new questions that arise during your exploration. For each question, create a visualization that might provide a useful answer. Then refine the visualization (by adding additional variables, changing the sort ordering or axis scales, filtering or subsetting data, etc.) to develop better perspectives explore unexpected observations, or sanity check your assumptions. You should repeat this process for each of your questions, and also feel free to revise your questions or branch off to explore new questions as the data warrants.
"""

import pandas
import os 
import seaborn as sns 
import matplotlib.pyplot as plt
df = pandas.read_csv("sample_data/imdb_top_1000.csv")
df.set_index("Series_Title", drop=False)
df.head(10)

print("number of rows", len(df))
df.columns

print("Number of missing values for each column.")
df.isnull().sum()

for col in df.columns:
  print("Descriptive statistics for", col)
  print(df[col].describe())
  print("\n\n")

plt.figure(figsize=(10,5))
sns.set(font_scale = 1.2)

chart = sns.catplot( x='Meta_score',
             kind="count", 
             height=8, 
             aspect=1.5, 
             data=df)
chart.set_xticklabels(rotation=90)

plt.figure(figsize=(10,5))
sns.set(font_scale = 0.8)

chart = sns.catplot( x='Released_Year',
             kind="count", 
             height=8, 
             aspect=1.5, 
             data=df, order=sorted(set(df['Released_Year'])))
chart.set_xticklabels(rotation=90)

mean_scores = df.groupby("Released_Year")['Meta_score'].agg("mean")
plt.figure(figsize=(20,7))
sns.set(font_scale = 1.17)
chart = sns.barplot(mean_scores.index, mean_scores.values)
plt.xticks(rotation=90)

df["Gross_int"] = df["Gross"].str.replace(",", "").astype(float)
total_gross = df.groupby("Released_Year")['Gross_int'].agg("sum")
plt.figure(figsize=(20,7))
sns.set(font_scale = 1.17)
chart = sns.barplot(total_gross.index, total_gross.values)
plt.xticks(rotation=90)

df["Runtime_minutes"] = df["Runtime"].str.replace("min", "").astype(int)
avg_length = df.groupby("Released_Year")['Runtime_minutes'].agg("mean")
plt.figure(figsize=(20,7))
sns.set(font_scale = 1.17)
chart = sns.barplot(avg_length.index, avg_length.values)
plt.xticks(rotation=90)

df.plot.scatter(x = "IMDB_Rating", y = "Meta_score")

sns.scatterplot(data=df.iloc[0:100], x="IMDB_Rating", y="Meta_score", hue = "Gross_int")

df["Popular Versus Expert"] = (df["IMDB_Rating"] * 10) - df["Meta_score"] 
# df.nlargest(10, "Popular Versus Expert")
df[ ["Series_Title", "Popular Versus Expert", "Gross", "Released_Year"] ].nlargest(20, "Popular Versus Expert")

df[ ["Series_Title", "Popular Versus Expert", "Gross", "Released_Year"] ].nsmallest(20, "Popular Versus Expert")

#Fixing the row with ReleasedYear == PG
df["Released_Year"] = pandas.to_numeric(df["Released_Year"], errors = "coerce") #any invalid value will turn to NaN
plt.figure(figsize=(13,7))
df2000_2010 = df[(df["Released_Year"]>= 2000) & (df["Released_Year"]<= 2010) ]
sns.scatterplot(data=df2000_2010, x="IMDB_Rating", y="Meta_score", hue="Runtime_minutes")

df.columns
print(df.Gross_int)

"""## **Final Deliverable**

Your final submission should consist of captioned visualizations detailing your most important insights. You will also work on writing and posting a blog to medium or your github website. Your “insights” can include important surprises or issues (such as data quality problems affecting your analysis) as well as responses to your analysis questions.

Each visualization image should be a screenshot accompanied with a title and descriptive caption (1-4 sentences long) describing the insight(s) learned from that view. Provide sufficient detail for each caption such that anyone could read through your report and understand what you’ve learned. You are free, but not required, to annotate your images to draw attention to specific features of the data. 

Do not submit a blog cluttered with everything little thing you tried. Submit a clean report that highlights the most important “milestones” in your exploration, which can include initial overviews, identification of data quality problems, confirmations of key assumptions, and potential “discoveries”. Your blog should only present the final dataset you analyzed and should not describe any iterations on earlier datasets you might have initially explored.

## **Data Sources**

There are a variety of data sources available online. Here are some possible sources to consider. If you have any questions about whether your dataset is appropriate, please talk to the TAs.

**Data is Plural** - Variety of datasets and sources covering many topics.

https://data.gov - U.S. Government open datasets.

U.S. Census Bureau - Census data - https://data.census.gov/

Federal Elections Commission - Campaign finance and expenditures. - https://www.fec.gov/data/

Federal Aviation Administration - FAA data - https://www.faa.gov/data_research/

https://www.kaggle.com/

https://archive.ics.uci.edu/ml/index.php

https://github.com/awesomedata/awesome-public-datasets - Awesome Public Datasets - Variety of public datasets.

Stanford Cable TV News Analyzer - We have recently released a tool that can be used to analyze who and what appears in the last decade of Cable TV News (i.e. CNN, Fox News, MSNBC). The site lets you download data as well which you could use to conduct further analysis. - https://tvnews.stanford.edu/data

### **Visualization Tool (matplotlib, seaborn, etc)**

One goal of this assignment is for you to learn to use and evaluate the effectiveness of these packages. In addition to these packages, you are free to also use other visualization tools as you see fit, for example, you could also take a look at Tableau.

### **Data Wrangling Tools**

The data you choose may require reformatting, transformation or cleaning prior to visualization. You can use Pandas for data preparation.

### **Grading**

Each submission will be graded based on both the analysis process and the included visualizations. Here are our grading criteria:

**Appropriate Data Assessment (5):** Overview/understanding of the data is built from transformations and appropriate assessment of data quality. Poses clear questions.

**Exploration Thoroughness (5):** Sufficient breadth of analysis, exploring questions in sufficient depth (with appropriate follow-up questions).

**Documentation (Blog) (5):** Clear documentation of exploratory process, including clearly written, understandable captions that communicate primary insights.

**Appropriate use of Numpy, Pandas, and Matplotlib (5)**  to ingest, clean, and present the data

### **Submission Details**

This is an individual assignment. You may not work in groups. The assignment is due on Sunday (03/07/2021)

To submit your assignment, download your notebook and zip all the necessary files(data files). Submit the zipped file to balckboard. Make sure the notebook and the zipped file is named in the format - EDA_LastName_FirstName. Be sure to include the link to access your blog in your notebook.

Also include the link to your notebook in the submission. 

We will provide more details on the blog during the next week of class.

**Note** - If the dataset is too large to be zipped and submitted on blackboard, only submit your notebook, add your dataset to your google drive and share a link to the file in your notebook.
"""